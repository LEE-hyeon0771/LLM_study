# Reranker

RAG 방식이 최신 정보를 반영하여 답변의 부정확성과 환각을 많이 줄일 수 있다는 점 때문에 현재 LLM에서 많이 채용되고 있다.

하지만, RAG 방식이 실제 복잡한 애플리케이션에 적용되면서 기본적인 RAG 파이프라인 만으로는 충분한 프로덕션 요구 사항을 충족시키기 어렵다는 문제점이 있다.

### RAG 문제점
1. 문서 임베딩 벡터 변환 과정에서의 손실 : 문서가 긴 경우 정해진 벡터 차원으로 표현이 어려워 정보 손실이 발생한다.
2. 검색 과정에서의 손실 : RAG의 검색 시간 단축을 위해 사용하는 ANNs 기술이 질문과 문서 사이의 관련성 체크 횟수를 줄임으로써 검색속도를 높일 수 있지만, 관련성 정확도 하락으로 정보의 손실 문제가 발생한다.

- Context 상위 k개 이내에서 질문에 대한 관련 정보가 누락될 수 있음 -> k의 숫자를 증가시키면서 해결이 가능함. but, 순서의 문제 발생.
- RAG의 정확도는 관련 정보가 Context 내에 존재하는 것이 중요한 것이 아닌, 순서가 핵심임(관련정보 내 상위권에 위치해야 좋은 답변이 가능하다는 것)

### Reranker
- RAG가 생성한 후보 문서들에 대해 질문에 대한 일관성과 관련성을 판단하여 문서의 우선 순위를 재정렬하는 것으로 답변의 정확도 상승을 기대하는 RAG pipeline의 Retrieval 성능 개선 방식

Reranker는 질문과 문서 사이의 유사도를 측정하며, 질문과 문서를 하나의 input으로 활용하는 Cross-encoder 방식을 사용한다.
해당 방식은 질문과 문서를 동시에 분석하는 self-attention을 사용함으로써 Bi-encoder 방식에 비해 더욱 정확한 유사도 측정이 가능하다.

-> 정확한 유사도 측정을 통해 질문-문서 사이의 관련성을 더욱 정교하게 측정할 수 있다.

- 단점 : 질문과 문서를 동시에 input으로 활용하며 분석하다보니 사용자가 질문을 하는 시점에서 모든 문서들이 질문과의 관련성을 측정 받게 된다. 이로 인해 연산량이 굉장히 많고 오래 걸릴 수밖에 없다.

- 해결책 : 이러한 문제점 극복을 위해 두단계 전략을 사용
1) 첫번째 단계 : 기존의 벡터 검색 방식으로 대규모 문서 중 질문과 관련성이 높다고 판단 될 수 있을만한 후보군을 검색한다.
2) 두번째 단계 : 후보군으로 검색된 문서들에 대해서만 reranker 기반으로 관련성을 재측정하게 된다.

### Reranker의 효과
- 성능 평가 지표 : Hit Rate, MRR
1) Hit Rate : Context 내 정답 존재 여부
2) MRR(Mean Reciprocal Rank) : Context 내 문서 중에서 질문과 관련성이 높은 문서의 순위가 높을수록 높은 값 반환

![image](https://github.com/LEE-hyeon0771/LLM_study/assets/84756586/38fc9a7e-eace-4961-bcfc-630664669327)

AWS tech blog의 결과 자료를 참고하여 첨부했습니다.

- 결과 해석
1. w/o reranker를 baseline으로 했을 때, Reranker가 존재할 경우 모든 수치가 향상 됨.
2. retriever의 Hit Rate와 MRR이 상승 -> Reranker를 활용할 때 질문에 대한 정답이 들어 있는 문서가 Context 내에서 상위권에 위치함.
3. Reranker similarity의 상승 : LLM의 답변 성능 향상

### 결론
Reranker는 질문과 문서의 동시 분석을 통해서 기존의 임베딩 유사도 대비 질문에 대한 관련 문서를 더욱 정확히 찾을 수 있다. 이러한 점을 통해서 양질의 Context 구성을 가능하게 했으며, LLM 답변 정확도 향상을 이끌어 낼 수 있다.

